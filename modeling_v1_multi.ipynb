{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from project_functions.sample_feed_v1_multi import SampleFeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "\n",
    "TRAINING_WINDOW_SIZE = 90\n",
    "PREDICTED_WINDOW_SIZE = 7\n",
    "\n",
    "N_FEATURES_SEQ = 3\n",
    "N_FEATURES_STC = 30\n",
    "\n",
    "N_SAMPLES = 4\n",
    "N_EPOCHS = 30\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_label = datetime.today().strftime(\"%m%d\")\n",
    "\n",
    "# Raw data\n",
    "\n",
    "features_train = dict(np.load(\"data/features_train.npz\", allow_pickle=True))\n",
    "features_valid = dict(np.load(\"data/features_valid.npz\", allow_pickle=True))\n",
    "\n",
    "# Calculated parameters\n",
    "\n",
    "n_rows_train = features_train['visits'].shape[0]\n",
    "\n",
    "steps_per_epoch = round(n_rows_train * N_SAMPLES / BATCH_SIZE)\n",
    "total_samples_per_page = N_SAMPLES * N_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Feed\n",
    "\n",
    "sample_feed = SampleFeed(\n",
    "    training_window_size = TRAINING_WINDOW_SIZE,\n",
    "    predicted_window_size = PREDICTED_WINDOW_SIZE,\n",
    "    samples_per_epoch = N_SAMPLES\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "Xy_train_gen = sample_feed.random_sample_stream(features_train)\n",
    "Xy_valid = sample_feed.random_sample_array(features_valid, samples_per_page=1, shuffle=False, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import regularizers\n",
    "from keras import Input, Model\n",
    "\n",
    "input_seq  = Input(shape=(TRAINING_WINDOW_SIZE, N_FEATURES_SEQ), name=\"TimeSeqInput\")\n",
    "x_seq      = layers.LSTM(units=32, return_sequences=True, recurrent_regularizer=regularizers.L2(0.01), name=\"LSTM_1\")(input_seq)\n",
    "x_seq      = layers.LSTM(units=16, return_sequences=False, recurrent_regularizer=regularizers.L2(0.01), name=\"LSTM_2\")(x_seq)\n",
    "\n",
    "model_seq  = Model(inputs=input_seq, outputs=x_seq, name=\"TimeSeqModel\")\n",
    "\n",
    "input_stc  = layers.Input(shape=(N_FEATURES_STC,), name=\"StaticInput\")\n",
    "x_stc      = layers.Dense(units=16, activation=\"relu\", name=\"DenseStatic_1\")(input_stc)\n",
    "\n",
    "model_stc  = Model(inputs=input_stc, outputs=x_stc, name=\"StaticModel\")\n",
    "\n",
    "x_comb     = layers.concatenate([model_seq.output, model_stc.output], name=\"Concat\")\n",
    "x_comb     = layers.Dense(units=32, activation=\"relu\", name=\"Dense_1\")(x_comb)\n",
    "x_comb     = layers.Dense(units=16, activation=\"relu\", name=\"Dense_2\")(x_comb)\n",
    "x_comb     = layers.Dense(units=PREDICTED_WINDOW_SIZE, activation=\"sigmoid\", name=\"Output\")(x_comb)\n",
    "\n",
    "model_comb = Model(inputs=[model_seq.input, model_stc.input], outputs=x_comb)\n",
    "\n",
    "model_comb.compile(\n",
    "    loss=losses.Huber(0.25), \n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3), \n",
    "    metrics=metrics.RootMeanSquaredError()\n",
    "    )\n",
    "\n",
    "model_comb.summary()\n",
    "\n",
    "model_callbacks = [\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, min_lr=1e-5),\n",
    "    callbacks.EarlyStopping(monitor='val_loss', patience=8),\n",
    "    callbacks.ModelCheckpoint(filepath=f\"models/checkpoints/{today_label}\" + \"{epoch:02d}-{val_root_mean_squared_error:.4f}.keras\", monitor='val_loss')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model_comb.fit(\n",
    "    x = Xy_train_gen,\n",
    "    validation_data = Xy_valid,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs = N_EPOCHS,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    callbacks = model_callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comb.save(f\"models/best_comb_{today_label}\", overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['loss'], color='black')\n",
    "plt.plot(model_history.history['val_loss'], color='blue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
